{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6524d53e-b3d6-41f2-9d1e-c39f98d52e1d",
   "metadata": {},
   "source": [
    "# Dataframe from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "460e7835-3700-4d4a-a0aa-212e268c34c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "import os\n",
    "import pandas as pd\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, MapType\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287badad-5bbd-4120-833e-372e4fffb5d3",
   "metadata": {},
   "source": [
    "## pyarrow lib provides a considerable performance improvment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e33eed2-c8f7-46f8-9943-cde7d53bc32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    ".config(\"spark.sql.execution.arrow.pyspark.enabled\", \"false\") \\\n",
    ".appName('test').master(\"spark://127.0.0.1:7077\")\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f927ff89-14fd-4527-837c-29c8d3e2892e",
   "metadata": {},
   "source": [
    "The JSON file test.js\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"name\": \"Andre\",\n",
    "        \"id\": 1,\n",
    "        \"sdictlist\":[{\"docid\":\"DOC001\", \"name\":\"bla001.txt\"}, {\"docid\":\"DOC002\", \"name\":\"bla002.txt\"}],\n",
    "        \"sarraylist\":[\"a\",\"b\",\"c\"]\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"name\": \"Noé\",\n",
    "        \"id\": 1,\n",
    "        \"sdictlist\":[{\"docid\":\"DOC003\", \"name\":\"bla003.txt\"}, {\"docid\":\"DOC004\", \"name\":\"bla004.txt\"}],\n",
    "        \"sarraylist\":[\"a\",\"b\",\"c\"]\n",
    "     \n",
    "    }\n",
    "]\n",
    "\n",
    "```\n",
    "\n",
    "The easiest way to read a local file is import it using Pandas and convert it into a DataFrame object later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a72facd-aea4-432e-bde5-753caa4efaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/Projects/Spark/spark-standalone/apps/venv/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:371: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------------------------------------------------------------------------------+----------+\n",
      "|name |id |sdictlist                                                                     |sarraylist|\n",
      "+-----+---+------------------------------------------------------------------------------+----------+\n",
      "|Andre|1  |[{name -> bla001.txt, docid -> DOC001}, {name -> bla002.txt, docid -> DOC002}]|[a, b, c] |\n",
      "|Noé  |1  |[{name -> bla003.txt, docid -> DOC003}, {name -> bla004.txt, docid -> DOC004}]|[a, b, c] |\n",
      "+-----+---+------------------------------------------------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading file using Pandas\n",
    "jdf = pd.read_json('test.js')\n",
    "# Converting to Spark dataframe\n",
    "sdf = spark.createDataFrame(jdf)\n",
    "# Showing the result\n",
    "sdf.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ba2ea4-eda9-4f53-924e-5f71e11f0899",
   "metadata": {},
   "source": [
    "User Defined Functions(UDF) is a way to parse information from a column. In this case, the docs inside the JSON file is available in a list of objects which is parsed by pySpark and convenient converted into Python data structure objects. In this case, a list of dictionaries which is eaiser to manipulate. Brilliant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a87b5f0-95cc-4d05-b742-a155f196a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf\n",
    "def extract_doc_udf(data_list):\n",
    "    n = list()\n",
    "    for li in data_list:\n",
    "        \n",
    "        n += [v for k,v in li.items() if k == 'name']\n",
    "\n",
    "    return ', '.join(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57fee3c9-fede-4649-a07e-9935bb82fd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------------------------------------------------------------------------------+----------+----------------------+\n",
      "|name |id |sdictlist                                                                     |sarraylist|udf_res               |\n",
      "+-----+---+------------------------------------------------------------------------------+----------+----------------------+\n",
      "|Andre|1  |[{name -> bla001.txt, docid -> DOC001}, {name -> bla002.txt, docid -> DOC002}]|[a, b, c] |bla001.txt, bla002.txt|\n",
      "|Noé  |1  |[{name -> bla003.txt, docid -> DOC003}, {name -> bla004.txt, docid -> DOC004}]|[a, b, c] |bla003.txt, bla004.txt|\n",
      "+-----+---+------------------------------------------------------------------------------+----------+----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Running the UDF called 'extract_doc_udf' and storing into a new column called 'udf_res'\n",
    "dfu = sdf.withColumn('udf_res', extract_doc_udf(F.col('sdictlist')))\n",
    "# Showing the result\n",
    "dfu.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56069cfc-2d38-4ef9-848f-d7116afc7d3e",
   "metadata": {},
   "source": [
    "Alterativelly, it's possible to use a simple Python function passing the dataframe row as a parameter. But, to do that is necessary to use RDD framework instead UDF and then convert it to DataFrame object later. This way is useful when you parse different fields in a row in iteractive way. But, note that the performance will drop considerably depending on data amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db3daafa-8e25-44d4-bb9a-4170e10c054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_doc_rdd(row):\n",
    "    d = row.asDict()\n",
    "    n = list()\n",
    "    if 'sdictlist' in d:\n",
    "        for li in d['sdictlist']:\n",
    "            n += [v for k,v in li.items() if k == 'name']\n",
    "\n",
    "        d['doc_names'] = ', '.join(n)\n",
    "\n",
    "    return Row(**d)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aba685e-ab0c-4b05-ab63-a2d9a97ee41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing 'extract_doc_rdd' using map method from rdd object\n",
    "rdd = sdf.rdd.map(extract_doc_rdd)\n",
    "# Converting into a dataframe object\n",
    "edf = rdd.toDF()\n",
    "# Showing the result\n",
    "edf.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
